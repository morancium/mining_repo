{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text cleaning techniques:\n",
    "1. Normalizing text -  case normalization\n",
    "2. Tokenize\n",
    "3. Removing stop words and punctuations\n",
    "4. Stemming and lemmetization\n",
    "\n",
    "Other steps include:\n",
    "1. dealing with numbers\n",
    "2. spell check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lyf\n",
    "#life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-47cbfcab36b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'word_list' is not defined"
     ]
    }
   ],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236736"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "word_list = words.words()\n",
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'west'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[236700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'commenter'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "revlst = [\"this\",\"is\",\"update\",\"good\",\"gud\",\"lyf\",\"life\",\"bdfgbvd\",\"zebra\",\"improvements\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndwords = [word for word in revlst if word not in word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lyf', 'bdfgbvd', 'improvements']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi welcome to the course on text analytics. text analytics is a very important course'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"Hi welcome to the course on Text Analytics. TEXT analYtics is a very important course\"\n",
    "text = txt.lower()\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization - Extracting smaller parts(tokens) from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'hotel', \"isn't\", 'awesome,', 'is', 'it?', 'it', \"couldn't\", 'have.', 'been', 'a', 'better', 'place', 'than', 'this']\n"
     ]
    }
   ],
   "source": [
    "txt1 = \"This hotel isn't awesome, is it? it couldn't have. been a better place than this\"\n",
    "text = txt1.split(\" \")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 problems here:\n",
    "    1. isnt \"is and not\" are not seperated out\n",
    "    2. punctuations are still part of the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk has different types of tokenizers:\n",
    "    1. word_tokenize\n",
    "    2. wordpunct_tokenize\n",
    "    3. tweettokenizer\n",
    "    4. regexp_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sumit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "txt1 = \"This hotel isn't good, is it? it couldn't have. been a better place than this!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'hotel', 'is', \"n't\", 'good', ',', 'is', 'it', '?', 'it', 'could', \"n't\", 'have', '.', 'been', 'a', 'better', 'place', 'than', 'this', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(txt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'hotel', 'isn', \"'\", 't', 'good', ',', 'is', 'it', '?', 'it', 'couldn', \"'\", 't', 'have', '.', 'been', 'a', 'better', 'place', 'than', 'this', '!!']\n"
     ]
    }
   ],
   "source": [
    "print(wordpunct_tokenize(txt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"LMAO #killing it, luv mah lyf YOLO LOL :D :D <3 @raju\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"Phone is good.battery is bad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Phone', 'is', 'good.battery', 'is', 'bad']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Phone', 'is', 'good.battery', 'is', 'bad']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"Living life king size #chilling #lifegoals #yolo #wanderlust\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you extract all the hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import regexp_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#chilling', '#lifegoals', '#yolo', '#wanderlust']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tokenize(message,\"#[\\w]+\")  # \"\"#[\\w]+\" start with a hash followed by one of the charecters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you get the hash tag from the text without printing the #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chilling', 'lifegoals', 'yolo', 'wanderlust']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tokenize(message,\"#([\\w]+)\") # small bracket in the pattern indicates scoping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "print(list(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "stop_nltk = stopwords.words(\"english\")\n",
    "print(stop_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_stop = list(punctuation) + stop_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(punct_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_stop.remove(\"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', 'not', 'able', 'to', 'work', 'today', ',', 'i', 'will', 'be', 'taking', 'off', '.']\n"
     ]
    }
   ],
   "source": [
    "txt = \"i am not able to work today, i will be taking off.\" \n",
    "print(word_tokenize(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not', 'able', 'work', 'today', 'taking']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in word_tokenize(txt) if word not in punct_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not', 'able', 'work', 'today', 'taking']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdemo = []\n",
    "for word in word_tokenize(txt):\n",
    "    if word not in punct_stop:\n",
    "        listdemo.append(word)\n",
    "listdemo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Take a string to its root form\n",
    "- it is Rule based and chops off the string at the end of the word\n",
    "- The stemmed word might not be part of the dictionary\n",
    "- 2 types:\n",
    "    1. porter stemmer - oldest one originally developed in 1979\n",
    "    2. snowball stemmer - sophasticated stemmer, supports multiple languages. faster than porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drive driving drives drived run running runs ran drove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer_p = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive hsdbfyhbdr drove\n"
     ]
    }
   ],
   "source": [
    "print(stemmer_p.stem('driving'), stemmer_p.stem('hsdbfyhbdring'),stemmer_p.stem('drove'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive drive drive driver\n"
     ]
    }
   ],
   "source": [
    "print(stemmer_p.stem('drive'),stemmer_p.stem('drives'),stemmer_p.stem('driving'),stemmer_p.stem('driver'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'etegdriv'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer_p.stem('etegdriving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'togeth'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer_p.stem('together')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'together driving drives driv'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer_p.stem('together driving drives drived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer_s = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive drive\n"
     ]
    }
   ],
   "source": [
    "print(stemmer_s.stem('driving'),stemmer_s.stem('drives'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possibl possibl huigyughvv\n"
     ]
    }
   ],
   "source": [
    "print(stemmer_s.stem('possibly'),stemmer_s.stem('possible'),stemmer_s.stem('huigyughvving'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'I mustered very all my drive, drove to the driving school'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'mustered', 'very', 'all', 'my', 'drive', ',', 'drove', 'to', 'the', 'driving', 'school']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(txt.lower())\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'muster', 'veri', 'all', 'my', 'drive', ',', 'drove', 'to', 'the', 'drive', 'school']\n",
      "['i', 'muster', 'veri', 'all', 'my', 'drive', ',', 'drove', 'to', 'the', 'drive', 'school']\n"
     ]
    }
   ],
   "source": [
    "print([stemmer_p.stem(word) for word in tokens])\n",
    "print([stemmer_s.stem(word) for word in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"he is very vary varied cry cries methodical drove orderly in his execution nation apple apples run runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'is', 'very', 'vary', 'varied', 'cry', 'cries', 'methodical', 'drove', 'orderly', 'in', 'his', 'execution', 'nation', 'apple', 'apples', 'run', 'runs']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(txt.lower())\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'is', 'veri', 'vari', 'vari', 'cri', 'cri', 'method', 'drove', 'orderli', 'in', 'hi', 'execut', 'nation', 'appl', 'appl', 'run', 'run']\n",
      "['he', 'is', 'veri', 'vari', 'vari', 'cri', 'cri', 'method', 'drove', 'order', 'in', 'his', 'execut', 'nation', 'appl', 'appl', 'run', 'run']\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print([stemmer_p.stem(word) for word in tokens ])\n",
    "print([stemmer_s.stem(word) for word in tokens ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer_s = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possibl possibl\n"
     ]
    }
   ],
   "source": [
    "print(stemmer_s.stem(\"possible\"),stemmer_s.stem(\"possibly\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ijdhdffbit'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer_s.stem(\"ijdhdffbition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'is', 'veri', 'vari', 'vari', 'cri', 'cri', 'method', 'drove', 'order', 'in', 'his', 'execut', 'nation', 'appl', 'appl', 'run', 'run']\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print([ stemmer_s.stem(word) for word in tokens ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stem the below sentences\n",
    "text = \"studies studying cries cry his execute\"\n",
    "text = \"studies studying cries cry crying his execute orderly university universal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['studies', 'studying', 'nation', 'cries', 'cry', 'crying', 'his', 'execute', 'execution', 'nation', 'orderly', 'university', 'universal', 'fhdofs', 'ijfbition']\n",
      "['studi', 'studi', 'nation', 'cri', 'cri', 'cri', 'his', 'execut', 'execut', 'nation', 'order', 'univers', 'univers', 'fhdof', 'ijfbit']\n",
      "['studi', 'studi', 'nation', 'cri', 'cri', 'cri', 'hi', 'execut', 'execut', 'nation', 'orderli', 'univers', 'univers', 'fhdof', 'ijfbit']\n"
     ]
    }
   ],
   "source": [
    "text = \"studies studying nation cries cry crying his execute execution nation orderly university universal fhdofs ijfbition\"\n",
    "tokens = word_tokenize(text.lower())\n",
    "print(tokens)\n",
    "print([stemmer_s.stem(word) for word in tokens])\n",
    "print([stemmer_p.stem(word) for word in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmetization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Like stemming, lemmatization takes the word to the root form called as lemma\n",
    "- It involves resolving words to their dictionary form\n",
    "- A lemma of a word is its dictionary form or canonical form\n",
    "- Lemmetizer in NLTK uses WordNet data set which comprises a list of synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sumit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drove'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm.lemmatize(\"drove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmetize the below sentences\n",
    "txt1 = \"he is very methodical and orderly in his execution\"\n",
    "txt2 = \"he is driving and drives the down of the drived vehicle\"\n",
    "txt3 = \"studies studying cries cry crying likes his execute\"\n",
    "txt4 = \"studies studying cries cry his likes execute orderly university universal\"\n",
    "txt5 = \"studies hxfhcjgcves studying cries crying sport orange oranges sports cry crying playing executing driving his execute orderly university universal apple apples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['studies', 'studying', 'cries', 'cry', 'crying', 'likes', 'his', 'execute']\n",
      "['study', 'studying', 'cry', 'cry', 'cry', 'like', 'his', 'execute']\n",
      "['study', 'study', 'cry', 'cry', 'cry', 'like', 'his', 'execute']\n",
      "['study', 'studying', 'cry', 'cry', 'cry', 'like', 'his', 'execute']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(txt3.lower())\n",
    "print(tokens)\n",
    "print([lemm.lemmatize(word) for word in word_tokenize(txt3.lower())])\n",
    "print([lemm.lemmatize(word, pos = \"v\") for word in word_tokenize(txt3.lower())])\n",
    "print([lemm.lemmatize(word, pos = \"n\") for word in word_tokenize(txt3.lower())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "?lemm.lemmatize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lemmetize is very aggresive in taking the word to the root form\n",
    "- if the word to be stemmed is not part of the dictionary, it leaves it as is\n",
    "- ensures that the meaning of the sentence is not altered\n",
    "- In some of the scenarios the no. distinct words after lemmetization could be same as before\n",
    "    - every step in text cleaning helps is reducing the number of words. but lemmetizer might not make a difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([lemm.lemmatize(word, pos = \"v\") for word in word_tokenize(txt5.lower()) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmetizer by defualt acts only on the noun forms, the below code\n",
    "# lemmetizes all the verb forms in the sentence\n",
    "print([lemm.lemmatize(word, pos='v') for word in word_tokenize(txt2.lower()) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('he', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('driving', 'VBG'),\n",
       " ('and', 'CC'),\n",
       " ('drives', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('down', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('drived', 'JJ'),\n",
       " ('vehicle', 'NN')]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize(\"he is driving and drives the down of the drived vehicle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt4 = \"studies studying cries cry his likes execute orderly ordered university universal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(word_tokenize(txt4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([lemm.lemmatize(word, pos = 'v') for word in word_tokenize(txt4.lower()) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([stemmer_s.stem(word) for word in word_tokenize(txt4.lower()) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer_s.stem(\"together\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(\"mobile's phones month's isn't good battery's backup bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Emojis to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emot in c:\\users\\sumit\\anaconda3\\lib\\site-packages (3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install emot\n",
    "import emot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"very bad phone :) :P :D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "emot_obj = emot.emot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value': [':)', ':P', ':D'],\n",
       " 'location': [[15, 17], [18, 20], [21, 23]],\n",
       " 'mean': ['Happy face or smiley',\n",
       "  'Tongue sticking out, cheeky, playful or blowing a raspberry',\n",
       "  'Laughing, big grin or laugh with glasses'],\n",
       " 'flag': True}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emot_obj.emoticons(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"I am honored to be with you today at your commencement from one of the finest universities in the world. I never graduated from college. Truth be told, this is the closest I’ve ever gotten to a college graduation. Today I want to tell you three stories from my life. That’s it. No big deal. Just three stories.\n",
    "\n",
    "The first story is about connecting the dots?\n",
    "\n",
    "I dropped out of Reed College after the first 6 months, but then stayed around as a drop-in for another 18 months or so before I really quit. So why did I drop out?\n",
    "\n",
    "It started before I was born. My biological mother was a young, unwed college graduate student, and she decided to put me up for adoption. She felt very strongly that I should be adopted by college graduates, so everything was all set for me to be adopted at birth by a lawyer and his wife. Except that when I popped out they decided at the last minute that they really wanted a girl. So my parents, who were on a waiting list, got a call in the middle of the night asking: “We have an unexpected baby boy; do you want him?” They said: “Of course.” My biological mother later found out that my mother had never graduated from college and that my father had never graduated from high school. She refused to sign the final adoption papers. She only relented a few months later when my parents promised that I would someday go to college.\n",
    "\n",
    "And 17 years later I did go to college. But I naively chose a college that was almost as expensive as Stanford, and all of my working-class parents’ savings were being spent on my college tuition. After six months, I couldn’t see the value in it. I had no idea what I wanted to do with my life and no idea how college was going to help me figure it out. And here I was spending all of the money my parents had saved their entire life. So I decided to drop out and trust that it would all work out OK. It was pretty scary at the time, but looking back it was one of the best decisions I ever made. The minute I dropped out I could stop taking the required classes that didn’t interest me, and begin dropping in on the ones that looked interesting.\n",
    "\n",
    "It wasn’t all romantic. I didn’t have a dorm room, so I slept on the floor in friends’ rooms, I returned Coke bottles for the 5¢ deposits to buy food with, and I would walk the 7 miles across town every Sunday night to get one good meal a week at the Hare Krishna temple. I loved it. And much of what I stumbled into by following my curiosity and intuition turned out to be priceless later on. Let me give you one example:\n",
    "\n",
    "Reed College at that time offered perhaps the best calligraphy instruction in the country. Throughout the campus every poster, every label on every drawer, was beautifully hand calligraphed. Because I had dropped out and didn’t have to take the normal classes, I decided to take a calligraphy class to learn how to do this. I learned about serif and sans serif typefaces, about varying the amount of space between different letter combinations, about what makes great typography great. It was beautiful, historical, artistically subtle in a way that science can’t capture, and I found it fascinating.\n",
    "\n",
    "None of this had even a hope of any practical application in my life. But 10 years later, when we were designing the first Macintosh computer, it all came back to me. And we designed it all into the Mac. It was the first computer with beautiful typography. If I had never dropped in on that single course in college, the Mac would have never had multiple typefaces or proportionally spaced fonts. And since Windows just copied the Mac, it’s likely that no personal computer would have them. If I had never dropped out, I would have never dropped in on this calligraphy class, and personal computers might not have the wonderful typography that they do. Of course it was impossible to connect the dots looking forward when I was in college. But it was very, very clear looking backward 10 years later.\n",
    "\n",
    "Again, you can’t connect the dots looking forward; you can only connect them looking backward. So you have to trust that the dots will somehow connect in your future. You have to trust in something — your gut, destiny, life, karma, whatever. This approach has never let me down, and it has made all the difference in my life.\n",
    "\n",
    "My second story is about love and loss.\n",
    "\n",
    "I was lucky — I found what I loved to do early in life. Woz and I started Apple in my parents’ garage when I was 20. We worked hard, and in 10 years Apple had grown from just the two of us in a garage into a $2 billion company with over 4,000 employees. We had just released our finest creation — the Macintosh — a year earlier, and I had just turned 30. And then I got fired. How can you get fired from a company you started? Well, as Apple grew we hired someone who I thought was very talented to run the company with me, and for the first year or so things went well. But then our visions of the future began to diverge and eventually we had a falling out. When we did, our Board of Directors sided with him. So at 30 I was out. And very publicly out. What had been the focus of my entire adult life was gone, and it was devastating.\n",
    "\n",
    "I really didn’t know what to do for a few months. I felt that I had let the previous generation of entrepreneurs down — that I had dropped the baton as it was being passed to me. I met with David Packard and Bob Noyce and tried to apologize for screwing up so badly. I was a very public failure, and I even thought about running away from the valley. But something slowly began to dawn on me — I still loved what I did. The turn of events at Apple had not changed that one bit. I had been rejected, but I was still in love. And so I decided to start over.\n",
    "\n",
    "I didn’t see it then, but it turned out that getting fired from Apple was the best thing that could have ever happened to me. The heaviness of being successful was replaced by the lightness of being a beginner again, less sure about everything. It freed me to enter one of the most creative periods of my life.\n",
    "\n",
    "During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the world’s first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I returned to Apple, and the technology we developed at NeXT is at the heart of Apple’s current renaissance. And Laurene and I have a wonderful family together.\n",
    "\n",
    "I’m pretty sure none of this would have happened if I hadn’t been fired from Apple. It was awful tasting medicine, but I guess the patient needed it. Sometimes life hits you in the head with a brick. Don’t lose faith. I’m convinced that the only thing that kept me going was that I loved what I did. You’ve got to find what you love. And that is as true for your work as it is for your lovers. Your work is going to fill a large part of your life, and the only way to be truly satisfied is to do what you believe is great work. And the only way to do great work is to love what you do. If you haven’t found it yet, keep looking. Don’t settle. As with all matters of the heart, you’ll know when you find it. And, like any great relationship, it just gets better and better as the years roll on. So keep looking until you find it. Don’t settle.\n",
    "\n",
    "My third story is about death.\n",
    "\n",
    "When I was 17, I read a quote that went something like: “If you live each day as if it was your last, someday you’ll most certainly be right.” It made an impression on me, and since then, for the past 33 years, I have looked in the mirror every morning and asked myself: “If today were the last day of my life, would I want to do what I am about to do today?” And whenever the answer has been “No” for too many days in a row, I know I need to change something.\n",
    "\n",
    "Remembering that I’ll be dead soon is the most important tool I’ve ever encountered to help me make the big choices in life. Because almost everything — all external expectations, all pride, all fear of embarrassment or failure — these things just fall away in the face of death, leaving only what is truly important. Remembering that you are going to die is the best way I know to avoid the trap of thinking you have something to lose. You are already naked. There is no reason not to follow your heart.\n",
    "\n",
    "About a year ago I was diagnosed with cancer. I had a scan at 7:30 in the morning, and it clearly showed a tumor on my pancreas. I didn’t even know what a pancreas was. The doctors told me this was almost certainly a type of cancer that is incurable, and that I should expect to live no longer than three to six months. My doctor advised me to go home and get my affairs in order, which is doctor’s code for prepare to die. It means to try to tell your kids everything you thought you’d have the next 10 years to tell them in just a few months. It means to make sure everything is buttoned up so that it will be as easy as possible for your family. It means to say your goodbyes.\n",
    "\n",
    "I lived with that diagnosis all day. Later that evening I had a biopsy, where they stuck an endoscope down my throat, through my stomach and into my intestines, put a needle into my pancreas and got a few cells from the tumor. I was sedated, but my wife, who was there, told me that when they viewed the cells under a microscope the doctors started crying because it turned out to be a very rare form of pancreatic cancer that is curable with surgery. I had the surgery and I’m fine now.\n",
    "\n",
    "This was the closest I’ve been to facing death, and I hope it’s the closest I get for a few more decades. Having lived through it, I can now say this to you with a bit more certainty than when death was a useful but purely intellectual concept:\n",
    "\n",
    "No one wants to die. Even people who want to go to heaven don’t want to die to get there. And yet death is the destination we all share. No one has ever escaped it. And that is as it should be, because Death is very likely the single best invention of Life. It is Life’s change agent. It clears out the old to make way for the new. Right now the new is you, but someday not too long from now, you will gradually become the old and be cleared away. Sorry to be so dramatic, but it is quite true.\n",
    "\n",
    "Your time is limited, so don’t waste it living someone else’s life. Don’t be trapped by dogma — which is living with the results of other people’s thinking. Don’t let the noise of others’ opinions drown out your own inner voice. And most important, have the courage to follow your heart and intuition. They somehow already know what you truly want to become. Everything else is secondary.\n",
    "\n",
    "When I was young, there was an amazing publication called The Whole Earth Catalog, which was one of the bibles of my generation. It was created by a fellow named Stewart Brand not far from here in Menlo Park, and he brought it to life with his poetic touch. This was in the late 1960s, before personal computers and desktop publishing, so it was all made with typewriters, scissors and Polaroid cameras. It was sort of like Google in paperback form, 35 years before Google came along: It was idealistic, and overflowing with neat tools and great notions.\n",
    "\n",
    "Stewart and his team put out several issues of The Whole Earth Catalog, and then when it had run its course, they put out a final issue. It was the mid-1970s, and I was your age. On the back cover of their final issue was a photograph of an early morning country road, the kind you might find yourself hitchhiking on if you were so adventurous. Beneath it were the words: “Stay Hungry. Stay Foolish.” It was their farewell message as they signed off. Stay Hungry. Stay Foolish. And I have always wished that for myself. And now, as you graduate to begin anew, I wish that for you.\n",
    "\n",
    "Stay Hungry. Stay Foolish.\n",
    "\n",
    "Thank you all very much.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentencetoken = nltk.sent_tokenize(paragraph)\n",
    "wordtoken = nltk.word_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am honored to be with you today at your commencement from one of the finest universities in the world.',\n",
       " 'I never graduated from college.',\n",
       " 'Truth be told, this is the closest I’ve ever gotten to a college graduation.',\n",
       " 'Today I want to tell you three stories from my life.',\n",
       " 'That’s it.',\n",
       " 'No big deal.',\n",
       " 'Just three stories.',\n",
       " 'The first story is about connecting the dots?',\n",
       " 'I dropped out of Reed College after the first 6 months, but then stayed around as a drop-in for another 18 months or so before I really quit.',\n",
       " 'So why did I drop out?',\n",
       " 'It started before I was born.',\n",
       " 'My biological mother was a young, unwed college graduate student, and she decided to put me up for adoption.',\n",
       " 'She felt very strongly that I should be adopted by college graduates, so everything was all set for me to be adopted at birth by a lawyer and his wife.',\n",
       " 'Except that when I popped out they decided at the last minute that they really wanted a girl.',\n",
       " 'So my parents, who were on a waiting list, got a call in the middle of the night asking: “We have an unexpected baby boy; do you want him?” They said: “Of course.” My biological mother later found out that my mother had never graduated from college and that my father had never graduated from high school.',\n",
       " 'She refused to sign the final adoption papers.',\n",
       " 'She only relented a few months later when my parents promised that I would someday go to college.',\n",
       " 'And 17 years later I did go to college.',\n",
       " 'But I naively chose a college that was almost as expensive as Stanford, and all of my working-class parents’ savings were being spent on my college tuition.',\n",
       " 'After six months, I couldn’t see the value in it.',\n",
       " 'I had no idea what I wanted to do with my life and no idea how college was going to help me figure it out.',\n",
       " 'And here I was spending all of the money my parents had saved their entire life.',\n",
       " 'So I decided to drop out and trust that it would all work out OK.',\n",
       " 'It was pretty scary at the time, but looking back it was one of the best decisions I ever made.',\n",
       " 'The minute I dropped out I could stop taking the required classes that didn’t interest me, and begin dropping in on the ones that looked interesting.',\n",
       " 'It wasn’t all romantic.',\n",
       " 'I didn’t have a dorm room, so I slept on the floor in friends’ rooms, I returned Coke bottles for the 5¢ deposits to buy food with, and I would walk the 7 miles across town every Sunday night to get one good meal a week at the Hare Krishna temple.',\n",
       " 'I loved it.',\n",
       " 'And much of what I stumbled into by following my curiosity and intuition turned out to be priceless later on.',\n",
       " 'Let me give you one example:\\n\\nReed College at that time offered perhaps the best calligraphy instruction in the country.',\n",
       " 'Throughout the campus every poster, every label on every drawer, was beautifully hand calligraphed.',\n",
       " 'Because I had dropped out and didn’t have to take the normal classes, I decided to take a calligraphy class to learn how to do this.',\n",
       " 'I learned about serif and sans serif typefaces, about varying the amount of space between different letter combinations, about what makes great typography great.',\n",
       " 'It was beautiful, historical, artistically subtle in a way that science can’t capture, and I found it fascinating.',\n",
       " 'None of this had even a hope of any practical application in my life.',\n",
       " 'But 10 years later, when we were designing the first Macintosh computer, it all came back to me.',\n",
       " 'And we designed it all into the Mac.',\n",
       " 'It was the first computer with beautiful typography.',\n",
       " 'If I had never dropped in on that single course in college, the Mac would have never had multiple typefaces or proportionally spaced fonts.',\n",
       " 'And since Windows just copied the Mac, it’s likely that no personal computer would have them.',\n",
       " 'If I had never dropped out, I would have never dropped in on this calligraphy class, and personal computers might not have the wonderful typography that they do.',\n",
       " 'Of course it was impossible to connect the dots looking forward when I was in college.',\n",
       " 'But it was very, very clear looking backward 10 years later.',\n",
       " 'Again, you can’t connect the dots looking forward; you can only connect them looking backward.',\n",
       " 'So you have to trust that the dots will somehow connect in your future.',\n",
       " 'You have to trust in something — your gut, destiny, life, karma, whatever.',\n",
       " 'This approach has never let me down, and it has made all the difference in my life.',\n",
       " 'My second story is about love and loss.',\n",
       " 'I was lucky — I found what I loved to do early in life.',\n",
       " 'Woz and I started Apple in my parents’ garage when I was 20.',\n",
       " 'We worked hard, and in 10 years Apple had grown from just the two of us in a garage into a $2 billion company with over 4,000 employees.',\n",
       " 'We had just released our finest creation — the Macintosh — a year earlier, and I had just turned 30.',\n",
       " 'And then I got fired.',\n",
       " 'How can you get fired from a company you started?',\n",
       " 'Well, as Apple grew we hired someone who I thought was very talented to run the company with me, and for the first year or so things went well.',\n",
       " 'But then our visions of the future began to diverge and eventually we had a falling out.',\n",
       " 'When we did, our Board of Directors sided with him.',\n",
       " 'So at 30 I was out.',\n",
       " 'And very publicly out.',\n",
       " 'What had been the focus of my entire adult life was gone, and it was devastating.',\n",
       " 'I really didn’t know what to do for a few months.',\n",
       " 'I felt that I had let the previous generation of entrepreneurs down — that I had dropped the baton as it was being passed to me.',\n",
       " 'I met with David Packard and Bob Noyce and tried to apologize for screwing up so badly.',\n",
       " 'I was a very public failure, and I even thought about running away from the valley.',\n",
       " 'But something slowly began to dawn on me — I still loved what I did.',\n",
       " 'The turn of events at Apple had not changed that one bit.',\n",
       " 'I had been rejected, but I was still in love.',\n",
       " 'And so I decided to start over.',\n",
       " 'I didn’t see it then, but it turned out that getting fired from Apple was the best thing that could have ever happened to me.',\n",
       " 'The heaviness of being successful was replaced by the lightness of being a beginner again, less sure about everything.',\n",
       " 'It freed me to enter one of the most creative periods of my life.',\n",
       " 'During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife.',\n",
       " 'Pixar went on to create the world’s first computer animated feature film, Toy Story, and is now the most successful animation studio in the world.',\n",
       " 'In a remarkable turn of events, Apple bought NeXT, I returned to Apple, and the technology we developed at NeXT is at the heart of Apple’s current renaissance.',\n",
       " 'And Laurene and I have a wonderful family together.',\n",
       " 'I’m pretty sure none of this would have happened if I hadn’t been fired from Apple.',\n",
       " 'It was awful tasting medicine, but I guess the patient needed it.',\n",
       " 'Sometimes life hits you in the head with a brick.',\n",
       " 'Don’t lose faith.',\n",
       " 'I’m convinced that the only thing that kept me going was that I loved what I did.',\n",
       " 'You’ve got to find what you love.',\n",
       " 'And that is as true for your work as it is for your lovers.',\n",
       " 'Your work is going to fill a large part of your life, and the only way to be truly satisfied is to do what you believe is great work.',\n",
       " 'And the only way to do great work is to love what you do.',\n",
       " 'If you haven’t found it yet, keep looking.',\n",
       " 'Don’t settle.',\n",
       " 'As with all matters of the heart, you’ll know when you find it.',\n",
       " 'And, like any great relationship, it just gets better and better as the years roll on.',\n",
       " 'So keep looking until you find it.',\n",
       " 'Don’t settle.',\n",
       " 'My third story is about death.',\n",
       " 'When I was 17, I read a quote that went something like: “If you live each day as if it was your last, someday you’ll most certainly be right.” It made an impression on me, and since then, for the past 33 years, I have looked in the mirror every morning and asked myself: “If today were the last day of my life, would I want to do what I am about to do today?” And whenever the answer has been “No” for too many days in a row, I know I need to change something.',\n",
       " 'Remembering that I’ll be dead soon is the most important tool I’ve ever encountered to help me make the big choices in life.',\n",
       " 'Because almost everything — all external expectations, all pride, all fear of embarrassment or failure — these things just fall away in the face of death, leaving only what is truly important.',\n",
       " 'Remembering that you are going to die is the best way I know to avoid the trap of thinking you have something to lose.',\n",
       " 'You are already naked.',\n",
       " 'There is no reason not to follow your heart.',\n",
       " 'About a year ago I was diagnosed with cancer.',\n",
       " 'I had a scan at 7:30 in the morning, and it clearly showed a tumor on my pancreas.',\n",
       " 'I didn’t even know what a pancreas was.',\n",
       " 'The doctors told me this was almost certainly a type of cancer that is incurable, and that I should expect to live no longer than three to six months.',\n",
       " 'My doctor advised me to go home and get my affairs in order, which is doctor’s code for prepare to die.',\n",
       " 'It means to try to tell your kids everything you thought you’d have the next 10 years to tell them in just a few months.',\n",
       " 'It means to make sure everything is buttoned up so that it will be as easy as possible for your family.',\n",
       " 'It means to say your goodbyes.',\n",
       " 'I lived with that diagnosis all day.',\n",
       " 'Later that evening I had a biopsy, where they stuck an endoscope down my throat, through my stomach and into my intestines, put a needle into my pancreas and got a few cells from the tumor.',\n",
       " 'I was sedated, but my wife, who was there, told me that when they viewed the cells under a microscope the doctors started crying because it turned out to be a very rare form of pancreatic cancer that is curable with surgery.',\n",
       " 'I had the surgery and I’m fine now.',\n",
       " 'This was the closest I’ve been to facing death, and I hope it’s the closest I get for a few more decades.',\n",
       " 'Having lived through it, I can now say this to you with a bit more certainty than when death was a useful but purely intellectual concept:\\n\\nNo one wants to die.',\n",
       " 'Even people who want to go to heaven don’t want to die to get there.',\n",
       " 'And yet death is the destination we all share.',\n",
       " 'No one has ever escaped it.',\n",
       " 'And that is as it should be, because Death is very likely the single best invention of Life.',\n",
       " 'It is Life’s change agent.',\n",
       " 'It clears out the old to make way for the new.',\n",
       " 'Right now the new is you, but someday not too long from now, you will gradually become the old and be cleared away.',\n",
       " 'Sorry to be so dramatic, but it is quite true.',\n",
       " 'Your time is limited, so don’t waste it living someone else’s life.',\n",
       " 'Don’t be trapped by dogma — which is living with the results of other people’s thinking.',\n",
       " 'Don’t let the noise of others’ opinions drown out your own inner voice.',\n",
       " 'And most important, have the courage to follow your heart and intuition.',\n",
       " 'They somehow already know what you truly want to become.',\n",
       " 'Everything else is secondary.',\n",
       " 'When I was young, there was an amazing publication called The Whole Earth Catalog, which was one of the bibles of my generation.',\n",
       " 'It was created by a fellow named Stewart Brand not far from here in Menlo Park, and he brought it to life with his poetic touch.',\n",
       " 'This was in the late 1960s, before personal computers and desktop publishing, so it was all made with typewriters, scissors and Polaroid cameras.',\n",
       " 'It was sort of like Google in paperback form, 35 years before Google came along: It was idealistic, and overflowing with neat tools and great notions.',\n",
       " 'Stewart and his team put out several issues of The Whole Earth Catalog, and then when it had run its course, they put out a final issue.',\n",
       " 'It was the mid-1970s, and I was your age.',\n",
       " 'On the back cover of their final issue was a photograph of an early morning country road, the kind you might find yourself hitchhiking on if you were so adventurous.',\n",
       " 'Beneath it were the words: “Stay Hungry.',\n",
       " 'Stay Foolish.” It was their farewell message as they signed off.',\n",
       " 'Stay Hungry.',\n",
       " 'Stay Foolish.',\n",
       " 'And I have always wished that for myself.',\n",
       " 'And now, as you graduate to begin anew, I wish that for you.',\n",
       " 'Stay Hungry.',\n",
       " 'Stay Foolish.',\n",
       " 'Thank you all very much.']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentencetoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'honored', 'to', 'be', 'with', 'you', 'today', 'at', 'your', 'commencement', 'from', 'one', 'of', 'the', 'finest', 'universities', 'in', 'the', 'world', '.', 'I', 'never', 'graduated', 'from', 'college', '.', 'Truth', 'be', 'told', ',', 'this', 'is', 'the', 'closest', 'I', '’', 've', 'ever', 'gotten', 'to', 'a', 'college', 'graduation', '.', 'Today', 'I', 'want', 'to', 'tell', 'you', 'three', 'stories', 'from', 'my', 'life', '.', 'That', '’', 's', 'it', '.', 'No', 'big', 'deal', '.', 'Just', 'three', 'stories', '.', 'The', 'first', 'story', 'is', 'about', 'connecting', 'the', 'dots', '?', 'I', 'dropped', 'out', 'of', 'Reed', 'College', 'after', 'the', 'first', '6', 'months', ',', 'but', 'then', 'stayed', 'around', 'as', 'a', 'drop-in', 'for', 'another', '18', 'months', 'or', 'so', 'before', 'I', 'really', 'quit', '.', 'So', 'why', 'did', 'I', 'drop', 'out', '?', 'It', 'started', 'before', 'I', 'was', 'born', '.', 'My', 'biological', 'mother', 'was', 'a', 'young', ',', 'unwed', 'college', 'graduate', 'student', ',', 'and', 'she', 'decided', 'to', 'put', 'me', 'up', 'for', 'adoption', '.', 'She', 'felt', 'very', 'strongly', 'that', 'I', 'should', 'be', 'adopted', 'by', 'college', 'graduates', ',', 'so', 'everything', 'was', 'all', 'set', 'for', 'me', 'to', 'be', 'adopted', 'at', 'birth', 'by', 'a', 'lawyer', 'and', 'his', 'wife', '.', 'Except', 'that', 'when', 'I', 'popped', 'out', 'they', 'decided', 'at', 'the', 'last', 'minute', 'that', 'they', 'really', 'wanted', 'a', 'girl', '.', 'So', 'my', 'parents', ',', 'who', 'were', 'on', 'a', 'waiting', 'list', ',', 'got', 'a', 'call', 'in', 'the', 'middle', 'of', 'the', 'night', 'asking', ':', '“', 'We', 'have', 'an', 'unexpected', 'baby', 'boy', ';', 'do', 'you', 'want', 'him', '?', '”', 'They', 'said', ':', '“', 'Of', 'course.', '”', 'My', 'biological', 'mother', 'later', 'found', 'out', 'that', 'my', 'mother', 'had', 'never', 'graduated', 'from', 'college', 'and', 'that', 'my', 'father', 'had', 'never', 'graduated', 'from', 'high', 'school', '.', 'She', 'refused', 'to', 'sign', 'the', 'final', 'adoption', 'papers', '.', 'She', 'only', 'relented', 'a', 'few', 'months', 'later', 'when', 'my', 'parents', 'promised', 'that', 'I', 'would', 'someday', 'go', 'to', 'college', '.', 'And', '17', 'years', 'later', 'I', 'did', 'go', 'to', 'college', '.', 'But', 'I', 'naively', 'chose', 'a', 'college', 'that', 'was', 'almost', 'as', 'expensive', 'as', 'Stanford', ',', 'and', 'all', 'of', 'my', 'working-class', 'parents', '’', 'savings', 'were', 'being', 'spent', 'on', 'my', 'college', 'tuition', '.', 'After', 'six', 'months', ',', 'I', 'couldn', '’', 't', 'see', 'the', 'value', 'in', 'it', '.', 'I', 'had', 'no', 'idea', 'what', 'I', 'wanted', 'to', 'do', 'with', 'my', 'life', 'and', 'no', 'idea', 'how', 'college', 'was', 'going', 'to', 'help', 'me', 'figure', 'it', 'out', '.', 'And', 'here', 'I', 'was', 'spending', 'all', 'of', 'the', 'money', 'my', 'parents', 'had', 'saved', 'their', 'entire', 'life', '.', 'So', 'I', 'decided', 'to', 'drop', 'out', 'and', 'trust', 'that', 'it', 'would', 'all', 'work', 'out', 'OK', '.', 'It', 'was', 'pretty', 'scary', 'at', 'the', 'time', ',', 'but', 'looking', 'back', 'it', 'was', 'one', 'of', 'the', 'best', 'decisions', 'I', 'ever', 'made', '.', 'The', 'minute', 'I', 'dropped', 'out', 'I', 'could', 'stop', 'taking', 'the', 'required', 'classes', 'that', 'didn', '’', 't', 'interest', 'me', ',', 'and', 'begin', 'dropping', 'in', 'on', 'the', 'ones', 'that', 'looked', 'interesting', '.', 'It', 'wasn', '’', 't', 'all', 'romantic', '.', 'I', 'didn', '’', 't', 'have', 'a', 'dorm', 'room', ',', 'so', 'I', 'slept', 'on', 'the', 'floor', 'in', 'friends', '’', 'rooms', ',', 'I', 'returned', 'Coke', 'bottles', 'for', 'the', '5¢', 'deposits', 'to', 'buy', 'food', 'with', ',', 'and', 'I', 'would', 'walk', 'the', '7', 'miles', 'across', 'town', 'every', 'Sunday', 'night', 'to', 'get', 'one', 'good', 'meal', 'a', 'week', 'at', 'the', 'Hare', 'Krishna', 'temple', '.', 'I', 'loved', 'it', '.', 'And', 'much', 'of', 'what', 'I', 'stumbled', 'into', 'by', 'following', 'my', 'curiosity', 'and', 'intuition', 'turned', 'out', 'to', 'be', 'priceless', 'later', 'on', '.', 'Let', 'me', 'give', 'you', 'one', 'example', ':', 'Reed', 'College', 'at', 'that', 'time', 'offered', 'perhaps', 'the', 'best', 'calligraphy', 'instruction', 'in', 'the', 'country', '.', 'Throughout', 'the', 'campus', 'every', 'poster', ',', 'every', 'label', 'on', 'every', 'drawer', ',', 'was', 'beautifully', 'hand', 'calligraphed', '.', 'Because', 'I', 'had', 'dropped', 'out', 'and', 'didn', '’', 't', 'have', 'to', 'take', 'the', 'normal', 'classes', ',', 'I', 'decided', 'to', 'take', 'a', 'calligraphy', 'class', 'to', 'learn', 'how', 'to', 'do', 'this', '.', 'I', 'learned', 'about', 'serif', 'and', 'sans', 'serif', 'typefaces', ',', 'about', 'varying', 'the', 'amount', 'of', 'space', 'between', 'different', 'letter', 'combinations', ',', 'about', 'what', 'makes', 'great', 'typography', 'great', '.', 'It', 'was', 'beautiful', ',', 'historical', ',', 'artistically', 'subtle', 'in', 'a', 'way', 'that', 'science', 'can', '’', 't', 'capture', ',', 'and', 'I', 'found', 'it', 'fascinating', '.', 'None', 'of', 'this', 'had', 'even', 'a', 'hope', 'of', 'any', 'practical', 'application', 'in', 'my', 'life', '.', 'But', '10', 'years', 'later', ',', 'when', 'we', 'were', 'designing', 'the', 'first', 'Macintosh', 'computer', ',', 'it', 'all', 'came', 'back', 'to', 'me', '.', 'And', 'we', 'designed', 'it', 'all', 'into', 'the', 'Mac', '.', 'It', 'was', 'the', 'first', 'computer', 'with', 'beautiful', 'typography', '.', 'If', 'I', 'had', 'never', 'dropped', 'in', 'on', 'that', 'single', 'course', 'in', 'college', ',', 'the', 'Mac', 'would', 'have', 'never', 'had', 'multiple', 'typefaces', 'or', 'proportionally', 'spaced', 'fonts', '.', 'And', 'since', 'Windows', 'just', 'copied', 'the', 'Mac', ',', 'it', '’', 's', 'likely', 'that', 'no', 'personal', 'computer', 'would', 'have', 'them', '.', 'If', 'I', 'had', 'never', 'dropped', 'out', ',', 'I', 'would', 'have', 'never', 'dropped', 'in', 'on', 'this', 'calligraphy', 'class', ',', 'and', 'personal', 'computers', 'might', 'not', 'have', 'the', 'wonderful', 'typography', 'that', 'they', 'do', '.', 'Of', 'course', 'it', 'was', 'impossible', 'to', 'connect', 'the', 'dots', 'looking', 'forward', 'when', 'I', 'was', 'in', 'college', '.', 'But', 'it', 'was', 'very', ',', 'very', 'clear', 'looking', 'backward', '10', 'years', 'later', '.', 'Again', ',', 'you', 'can', '’', 't', 'connect', 'the', 'dots', 'looking', 'forward', ';', 'you', 'can', 'only', 'connect', 'them', 'looking', 'backward', '.', 'So', 'you', 'have', 'to', 'trust', 'that', 'the', 'dots', 'will', 'somehow', 'connect', 'in', 'your', 'future', '.', 'You', 'have', 'to', 'trust', 'in', 'something', '—', 'your', 'gut', ',', 'destiny', ',', 'life', ',', 'karma', ',', 'whatever', '.', 'This', 'approach', 'has', 'never', 'let', 'me', 'down', ',', 'and', 'it', 'has', 'made', 'all', 'the', 'difference', 'in', 'my', 'life', '.', 'My', 'second', 'story', 'is', 'about', 'love', 'and', 'loss', '.', 'I', 'was', 'lucky', '—', 'I', 'found', 'what', 'I', 'loved', 'to', 'do', 'early', 'in', 'life', '.', 'Woz', 'and', 'I', 'started', 'Apple', 'in', 'my', 'parents', '’', 'garage', 'when', 'I', 'was', '20', '.', 'We', 'worked', 'hard', ',', 'and', 'in', '10', 'years', 'Apple', 'had', 'grown', 'from', 'just', 'the', 'two', 'of', 'us', 'in', 'a', 'garage', 'into', 'a', '$', '2', 'billion', 'company', 'with', 'over', '4,000', 'employees', '.', 'We', 'had', 'just', 'released', 'our', 'finest', 'creation', '—', 'the', 'Macintosh', '—', 'a', 'year', 'earlier', ',', 'and', 'I', 'had', 'just', 'turned', '30', '.', 'And', 'then', 'I', 'got', 'fired', '.', 'How', 'can', 'you', 'get', 'fired', 'from', 'a', 'company', 'you', 'started', '?', 'Well', ',', 'as', 'Apple', 'grew', 'we', 'hired', 'someone', 'who', 'I', 'thought', 'was', 'very', 'talented', 'to', 'run', 'the', 'company', 'with', 'me', ',', 'and', 'for', 'the', 'first', 'year', 'or', 'so', 'things', 'went', 'well', '.', 'But', 'then', 'our', 'visions', 'of', 'the', 'future', 'began', 'to', 'diverge', 'and', 'eventually', 'we', 'had', 'a', 'falling', 'out', '.', 'When', 'we', 'did', ',', 'our', 'Board', 'of', 'Directors', 'sided', 'with', 'him', '.', 'So', 'at', '30', 'I', 'was', 'out', '.', 'And', 'very', 'publicly', 'out', '.', 'What', 'had', 'been', 'the', 'focus', 'of', 'my', 'entire', 'adult', 'life', 'was', 'gone', ',', 'and', 'it', 'was', 'devastating', '.', 'I', 'really', 'didn', '’', 't', 'know', 'what', 'to', 'do', 'for', 'a', 'few', 'months', '.', 'I', 'felt', 'that', 'I', 'had', 'let', 'the', 'previous', 'generation', 'of', 'entrepreneurs', 'down', '—', 'that', 'I', 'had', 'dropped', 'the', 'baton', 'as', 'it', 'was', 'being', 'passed', 'to', 'me', '.', 'I', 'met', 'with', 'David', 'Packard', 'and', 'Bob', 'Noyce', 'and', 'tried', 'to', 'apologize', 'for', 'screwing', 'up', 'so', 'badly', '.', 'I', 'was', 'a', 'very', 'public', 'failure', ',', 'and', 'I', 'even', 'thought', 'about', 'running', 'away', 'from', 'the', 'valley', '.', 'But', 'something', 'slowly', 'began', 'to', 'dawn', 'on', 'me', '—', 'I', 'still', 'loved', 'what', 'I', 'did', '.', 'The', 'turn', 'of', 'events', 'at', 'Apple', 'had', 'not', 'changed', 'that', 'one', 'bit', '.', 'I', 'had', 'been', 'rejected', ',', 'but', 'I', 'was', 'still', 'in', 'love', '.', 'And', 'so', 'I', 'decided', 'to', 'start', 'over', '.', 'I', 'didn', '’', 't', 'see', 'it', 'then', ',', 'but', 'it', 'turned', 'out', 'that', 'getting', 'fired', 'from', 'Apple', 'was', 'the', 'best', 'thing', 'that', 'could', 'have', 'ever', 'happened', 'to', 'me', '.', 'The', 'heaviness', 'of', 'being', 'successful', 'was', 'replaced', 'by', 'the', 'lightness', 'of', 'being', 'a', 'beginner', 'again', ',', 'less', 'sure', 'about', 'everything', '.', 'It', 'freed', 'me', 'to', 'enter', 'one', 'of', 'the', 'most', 'creative', 'periods', 'of', 'my', 'life', '.', 'During', 'the', 'next', 'five', 'years', ',', 'I', 'started', 'a', 'company', 'named', 'NeXT', ',', 'another', 'company', 'named', 'Pixar', ',', 'and', 'fell', 'in', 'love', 'with', 'an', 'amazing', 'woman', 'who', 'would', 'become', 'my', 'wife', '.', 'Pixar', 'went', 'on', 'to', 'create', 'the', 'world', '’', 's', 'first', 'computer', 'animated', 'feature', 'film', ',', 'Toy', 'Story', ',', 'and', 'is', 'now', 'the', 'most', 'successful', 'animation', 'studio', 'in', 'the', 'world', '.', 'In', 'a', 'remarkable', 'turn', 'of', 'events', ',', 'Apple', 'bought', 'NeXT', ',', 'I', 'returned', 'to', 'Apple', ',', 'and', 'the', 'technology', 'we', 'developed', 'at', 'NeXT', 'is', 'at', 'the', 'heart', 'of', 'Apple', '’', 's', 'current', 'renaissance', '.', 'And', 'Laurene', 'and', 'I', 'have', 'a', 'wonderful', 'family', 'together', '.', 'I', '’', 'm', 'pretty', 'sure', 'none', 'of', 'this', 'would', 'have', 'happened', 'if', 'I', 'hadn', '’', 't', 'been', 'fired', 'from', 'Apple', '.', 'It', 'was', 'awful', 'tasting', 'medicine', ',', 'but', 'I', 'guess', 'the', 'patient', 'needed', 'it', '.', 'Sometimes', 'life', 'hits', 'you', 'in', 'the', 'head', 'with', 'a', 'brick', '.', 'Don', '’', 't', 'lose', 'faith', '.', 'I', '’', 'm', 'convinced', 'that', 'the', 'only', 'thing', 'that', 'kept', 'me', 'going', 'was', 'that', 'I', 'loved', 'what', 'I', 'did', '.', 'You', '’', 've', 'got', 'to', 'find', 'what', 'you', 'love', '.', 'And', 'that', 'is', 'as', 'true', 'for', 'your', 'work', 'as', 'it', 'is', 'for', 'your', 'lovers', '.', 'Your', 'work', 'is', 'going', 'to', 'fill', 'a', 'large', 'part', 'of', 'your', 'life', ',', 'and', 'the', 'only', 'way', 'to', 'be', 'truly', 'satisfied', 'is', 'to', 'do', 'what', 'you', 'believe', 'is', 'great', 'work', '.', 'And', 'the', 'only', 'way', 'to', 'do', 'great', 'work', 'is', 'to', 'love', 'what', 'you', 'do', '.', 'If', 'you', 'haven', '’', 't', 'found', 'it', 'yet', ',', 'keep', 'looking', '.', 'Don', '’', 't', 'settle', '.', 'As', 'with', 'all', 'matters', 'of', 'the', 'heart', ',', 'you', '’', 'll', 'know', 'when', 'you', 'find', 'it', '.', 'And', ',', 'like', 'any', 'great', 'relationship', ',', 'it', 'just', 'gets', 'better', 'and', 'better', 'as', 'the', 'years', 'roll', 'on', '.', 'So', 'keep', 'looking', 'until', 'you', 'find', 'it', '.', 'Don', '’', 't', 'settle', '.', 'My', 'third', 'story', 'is', 'about', 'death', '.', 'When', 'I', 'was', '17', ',', 'I', 'read', 'a', 'quote', 'that', 'went', 'something', 'like', ':', '“', 'If', 'you', 'live', 'each', 'day', 'as', 'if', 'it', 'was', 'your', 'last', ',', 'someday', 'you', '’', 'll', 'most', 'certainly', 'be', 'right.', '”', 'It', 'made', 'an', 'impression', 'on', 'me', ',', 'and', 'since', 'then', ',', 'for', 'the', 'past', '33', 'years', ',', 'I', 'have', 'looked', 'in', 'the', 'mirror', 'every', 'morning', 'and', 'asked', 'myself', ':', '“', 'If', 'today', 'were', 'the', 'last', 'day', 'of', 'my', 'life', ',', 'would', 'I', 'want', 'to', 'do', 'what', 'I', 'am', 'about', 'to', 'do', 'today', '?', '”', 'And', 'whenever', 'the', 'answer', 'has', 'been', '“', 'No', '”', 'for', 'too', 'many', 'days', 'in', 'a', 'row', ',', 'I', 'know', 'I', 'need', 'to', 'change', 'something', '.', 'Remembering', 'that', 'I', '’', 'll', 'be', 'dead', 'soon', 'is', 'the', 'most', 'important', 'tool', 'I', '’', 've', 'ever', 'encountered', 'to', 'help', 'me', 'make', 'the', 'big', 'choices', 'in', 'life', '.', 'Because', 'almost', 'everything', '—', 'all', 'external', 'expectations', ',', 'all', 'pride', ',', 'all', 'fear', 'of', 'embarrassment', 'or', 'failure', '—', 'these', 'things', 'just', 'fall', 'away', 'in', 'the', 'face', 'of', 'death', ',', 'leaving', 'only', 'what', 'is', 'truly', 'important', '.', 'Remembering', 'that', 'you', 'are', 'going', 'to', 'die', 'is', 'the', 'best', 'way', 'I', 'know', 'to', 'avoid', 'the', 'trap', 'of', 'thinking', 'you', 'have', 'something', 'to', 'lose', '.', 'You', 'are', 'already', 'naked', '.', 'There', 'is', 'no', 'reason', 'not', 'to', 'follow', 'your', 'heart', '.', 'About', 'a', 'year', 'ago', 'I', 'was', 'diagnosed', 'with', 'cancer', '.', 'I', 'had', 'a', 'scan', 'at', '7:30', 'in', 'the', 'morning', ',', 'and', 'it', 'clearly', 'showed', 'a', 'tumor', 'on', 'my', 'pancreas', '.', 'I', 'didn', '’', 't', 'even', 'know', 'what', 'a', 'pancreas', 'was', '.', 'The', 'doctors', 'told', 'me', 'this', 'was', 'almost', 'certainly', 'a', 'type', 'of', 'cancer', 'that', 'is', 'incurable', ',', 'and', 'that', 'I', 'should', 'expect', 'to', 'live', 'no', 'longer', 'than', 'three', 'to', 'six', 'months', '.', 'My', 'doctor', 'advised', 'me', 'to', 'go', 'home', 'and', 'get', 'my', 'affairs', 'in', 'order', ',', 'which', 'is', 'doctor', '’', 's', 'code', 'for', 'prepare', 'to', 'die', '.', 'It', 'means', 'to', 'try', 'to', 'tell', 'your', 'kids', 'everything', 'you', 'thought', 'you', '’', 'd', 'have', 'the', 'next', '10', 'years', 'to', 'tell', 'them', 'in', 'just', 'a', 'few', 'months', '.', 'It', 'means', 'to', 'make', 'sure', 'everything', 'is', 'buttoned', 'up', 'so', 'that', 'it', 'will', 'be', 'as', 'easy', 'as', 'possible', 'for', 'your', 'family', '.', 'It', 'means', 'to', 'say', 'your', 'goodbyes', '.', 'I', 'lived', 'with', 'that', 'diagnosis', 'all', 'day', '.', 'Later', 'that', 'evening', 'I', 'had', 'a', 'biopsy', ',', 'where', 'they', 'stuck', 'an', 'endoscope', 'down', 'my', 'throat', ',', 'through', 'my', 'stomach', 'and', 'into', 'my', 'intestines', ',', 'put', 'a', 'needle', 'into', 'my', 'pancreas', 'and', 'got', 'a', 'few', 'cells', 'from', 'the', 'tumor', '.', 'I', 'was', 'sedated', ',', 'but', 'my', 'wife', ',', 'who', 'was', 'there', ',', 'told', 'me', 'that', 'when', 'they', 'viewed', 'the', 'cells', 'under', 'a', 'microscope', 'the', 'doctors', 'started', 'crying', 'because', 'it', 'turned', 'out', 'to', 'be', 'a', 'very', 'rare', 'form', 'of', 'pancreatic', 'cancer', 'that', 'is', 'curable', 'with', 'surgery', '.', 'I', 'had', 'the', 'surgery', 'and', 'I', '’', 'm', 'fine', 'now', '.', 'This', 'was', 'the', 'closest', 'I', '’', 've', 'been', 'to', 'facing', 'death', ',', 'and', 'I', 'hope', 'it', '’', 's', 'the', 'closest', 'I', 'get', 'for', 'a', 'few', 'more', 'decades', '.', 'Having', 'lived', 'through', 'it', ',', 'I', 'can', 'now', 'say', 'this', 'to', 'you', 'with', 'a', 'bit', 'more', 'certainty', 'than', 'when', 'death', 'was', 'a', 'useful', 'but', 'purely', 'intellectual', 'concept', ':', 'No', 'one', 'wants', 'to', 'die', '.', 'Even', 'people', 'who', 'want', 'to', 'go', 'to', 'heaven', 'don', '’', 't', 'want', 'to', 'die', 'to', 'get', 'there', '.', 'And', 'yet', 'death', 'is', 'the', 'destination', 'we', 'all', 'share', '.', 'No', 'one', 'has', 'ever', 'escaped', 'it', '.', 'And', 'that', 'is', 'as', 'it', 'should', 'be', ',', 'because', 'Death', 'is', 'very', 'likely', 'the', 'single', 'best', 'invention', 'of', 'Life', '.', 'It', 'is', 'Life', '’', 's', 'change', 'agent', '.', 'It', 'clears', 'out', 'the', 'old', 'to', 'make', 'way', 'for', 'the', 'new', '.', 'Right', 'now', 'the', 'new', 'is', 'you', ',', 'but', 'someday', 'not', 'too', 'long', 'from', 'now', ',', 'you', 'will', 'gradually', 'become', 'the', 'old', 'and', 'be', 'cleared', 'away', '.', 'Sorry', 'to', 'be', 'so', 'dramatic', ',', 'but', 'it', 'is', 'quite', 'true', '.', 'Your', 'time', 'is', 'limited', ',', 'so', 'don', '’', 't', 'waste', 'it', 'living', 'someone', 'else', '’', 's', 'life', '.', 'Don', '’', 't', 'be', 'trapped', 'by', 'dogma', '—', 'which', 'is', 'living', 'with', 'the', 'results', 'of', 'other', 'people', '’', 's', 'thinking', '.', 'Don', '’', 't', 'let', 'the', 'noise', 'of', 'others', '’', 'opinions', 'drown', 'out', 'your', 'own', 'inner', 'voice', '.', 'And', 'most', 'important', ',', 'have', 'the', 'courage', 'to', 'follow', 'your', 'heart', 'and', 'intuition', '.', 'They', 'somehow', 'already', 'know', 'what', 'you', 'truly', 'want', 'to', 'become', '.', 'Everything', 'else', 'is', 'secondary', '.', 'When', 'I', 'was', 'young', ',', 'there', 'was', 'an', 'amazing', 'publication', 'called', 'The', 'Whole', 'Earth', 'Catalog', ',', 'which', 'was', 'one', 'of', 'the', 'bibles', 'of', 'my', 'generation', '.', 'It', 'was', 'created', 'by', 'a', 'fellow', 'named', 'Stewart', 'Brand', 'not', 'far', 'from', 'here', 'in', 'Menlo', 'Park', ',', 'and', 'he', 'brought', 'it', 'to', 'life', 'with', 'his', 'poetic', 'touch', '.', 'This', 'was', 'in', 'the', 'late', '1960s', ',', 'before', 'personal', 'computers', 'and', 'desktop', 'publishing', ',', 'so', 'it', 'was', 'all', 'made', 'with', 'typewriters', ',', 'scissors', 'and', 'Polaroid', 'cameras', '.', 'It', 'was', 'sort', 'of', 'like', 'Google', 'in', 'paperback', 'form', ',', '35', 'years', 'before', 'Google', 'came', 'along', ':', 'It', 'was', 'idealistic', ',', 'and', 'overflowing', 'with', 'neat', 'tools', 'and', 'great', 'notions', '.', 'Stewart', 'and', 'his', 'team', 'put', 'out', 'several', 'issues', 'of', 'The', 'Whole', 'Earth', 'Catalog', ',', 'and', 'then', 'when', 'it', 'had', 'run', 'its', 'course', ',', 'they', 'put', 'out', 'a', 'final', 'issue', '.', 'It', 'was', 'the', 'mid-1970s', ',', 'and', 'I', 'was', 'your', 'age', '.', 'On', 'the', 'back', 'cover', 'of', 'their', 'final', 'issue', 'was', 'a', 'photograph', 'of', 'an', 'early', 'morning', 'country', 'road', ',', 'the', 'kind', 'you', 'might', 'find', 'yourself', 'hitchhiking', 'on', 'if', 'you', 'were', 'so', 'adventurous', '.', 'Beneath', 'it', 'were', 'the', 'words', ':', '“', 'Stay', 'Hungry', '.', 'Stay', 'Foolish.', '”', 'It', 'was', 'their', 'farewell', 'message', 'as', 'they', 'signed', 'off', '.', 'Stay', 'Hungry', '.', 'Stay', 'Foolish', '.', 'And', 'I', 'have', 'always', 'wished', 'that', 'for', 'myself', '.', 'And', 'now', ',', 'as', 'you', 'graduate', 'to', 'begin', 'anew', ',', 'I', 'wish', 'that', 'for', 'you', '.', 'Stay', 'Hungry', '.', 'Stay', 'Foolish', '.', 'Thank', 'you', 'all', 'very', 'much', '.']\n"
     ]
    }
   ],
   "source": [
    "print(wordtoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
